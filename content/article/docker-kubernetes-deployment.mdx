---
title: "Modern Application Deployment with Docker and Kubernetes"
date: "2024-03-20"
description: "Master containerization and orchestration by learning how to deploy scalable applications using Docker and Kubernetes in production environments."
bannerImage: "https://images.ctfassets.net/kftzwdyauwt9/6hzNVLjPZq56rOlD33UwPs/bcfb01b68d985564659658e634cdcc1d/oai_GA_Stories_1.1_-_Introducing_the_Teen_Safety_Blueprint.png"
draft: false
---

> **⚠️ Note:** This is a sample article to test UI, generated by AI.

In today's cloud-native world, understanding containerization and orchestration is essential for deploying scalable, reliable applications. This guide will take you from Docker basics to deploying a production-ready application on Kubernetes.

## Why Containers?

Containers have revolutionized how we deploy applications by providing:

- **Consistency**: Same environment from development to production
- **Isolation**: Each container runs independently
- **Portability**: Run anywhere - laptop, cloud, on-premises
- **Efficiency**: Share OS kernel, start in seconds
- **Scalability**: Easy to scale horizontally

## Getting Started with Docker

### Installing Docker

```bash
# macOS (using Homebrew)
brew install --cask docker

# Ubuntu
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# Verify installation
docker --version
docker run hello-world
```

### Writing Your First Dockerfile

Let's containerize a Node.js application:

```dockerfile
# Dockerfile
FROM node:18-alpine AS builder

# Set working directory
WORKDIR /app

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm ci --only=production

# Copy application code
COPY . .

# Build application (if needed)
RUN npm run build

# Production stage
FROM node:18-alpine

WORKDIR /app

# Copy from builder
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/node_modules ./node_modules
COPY --from=builder /app/package*.json ./

# Create non-root user
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nodejs -u 1001

USER nodejs

# Expose port
EXPOSE 3000

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node healthcheck.js

# Start application
CMD ["node", "dist/server.js"]
```

### Docker Compose for Local Development

```yaml
# docker-compose.yml
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=development
      - DATABASE_URL=postgresql://postgres:password@db:5432/myapp
    volumes:
      - ./src:/app/src
    depends_on:
      - db
      - redis
    networks:
      - app-network

  db:
    image: postgres:15-alpine
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=myapp
    volumes:
      - postgres-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - app-network

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - app-network

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - app
    networks:
      - app-network

volumes:
  postgres-data:
  redis-data:

networks:
  app-network:
    driver: bridge
```

### Building and Running

```bash
# Build image
docker build -t myapp:latest .

# Run container
docker run -p 3000:3000 myapp:latest

# Using Docker Compose
docker-compose up -d

# View logs
docker-compose logs -f app

# Stop services
docker-compose down
```

## Introduction to Kubernetes

Kubernetes (K8s) is a container orchestration platform that automates deployment, scaling, and management of containerized applications.

### Core Concepts

- **Pod**: Smallest deployable unit, contains one or more containers
- **Deployment**: Manages desired state of Pods
- **Service**: Exposes Pods to network traffic
- **ConfigMap/Secret**: Configuration and sensitive data management
- **Ingress**: HTTP/HTTPS routing to services
- **Namespace**: Virtual clusters for resource isolation

<ImageWithCaption
  src="https://images.ctfassets.net/kftzwdyauwt9/6hzNVLjPZq56rOlD33UwPs/bcfb01b68d985564659658e634cdcc1d/oai_GA_Stories_1.1_-_Introducing_the_Teen_Safety_Blueprint.png"
  alt="Kubernetes Architecture Overview diagram showing pods, services, and deployments"
  caption="Kubernetes Architecture Overview"
>
</ImageWithCaption>

## Kubernetes Deployment Configuration

### Deployment Manifest

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
  namespace: production
  labels:
    app: myapp
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp
        image: myregistry.com/myapp:v1.0.0
        ports:
        - containerPort: 3000
          name: http
        env:
        - name: NODE_ENV
          value: "production"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: connection-string
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5
```

### Service Configuration

```yaml
# k8s/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
  namespace: production
spec:
  type: ClusterIP
  selector:
    app: myapp
  ports:
  - port: 80
    targetPort: 3000
    protocol: TCP
    name: http
  sessionAffinity: ClientIP
```

### Ingress Configuration

```yaml
# k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: myapp-ingress
  namespace: production
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/rate-limit: "100"
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - myapp.example.com
    secretName: myapp-tls
  rules:
  - host: myapp.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: myapp-service
            port:
              number: 80
```

## ConfigMaps and Secrets

```yaml
# k8s/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: myapp-config
  namespace: production
data:
  LOG_LEVEL: "info"
  API_TIMEOUT: "30000"
  FEATURE_FLAG_NEW_UI: "true"

---
# k8s/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: db-credentials
  namespace: production
type: Opaque
stringData:
  connection-string: "postgresql://user:password@db:5432/myapp"
  api-key: "your-secret-api-key"
```

## Deploying to Kubernetes

```bash
# Create namespace
kubectl create namespace production

# Apply configurations
kubectl apply -f k8s/configmap.yaml
kubectl apply -f k8s/secret.yaml
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml
kubectl apply -f k8s/ingress.yaml

# Check deployment status
kubectl get pods -n production
kubectl get deployments -n production
kubectl get services -n production

# View logs
kubectl logs -f deployment/myapp -n production

# Scale deployment
kubectl scale deployment/myapp --replicas=5 -n production

# Rolling update
kubectl set image deployment/myapp myapp=myregistry.com/myapp:v1.1.0 -n production

# Rollback if needed
kubectl rollout undo deployment/myapp -n production
```

## Monitoring and Observability

### Horizontal Pod Autoscaler

```yaml
# k8s/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: myapp-hpa
  namespace: production
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

## Best Practices

### Container Best Practices

1. **Use Official Base Images**: Start with official, minimal images
2. **Run as Non-Root**: Create dedicated user for security
3. **Multi-Stage Builds**: Reduce image size and attack surface
4. **Scan for Vulnerabilities**: Use tools like Trivy or Snyk
5. **Tag Images Properly**: Use semantic versioning

### Kubernetes Best Practices

1. **Resource Limits**: Always set resource requests and limits
2. **Health Checks**: Implement liveness and readiness probes
3. **Use Namespaces**: Isolate environments and teams
4. **ConfigMaps for Config**: Separate configuration from code
5. **Secrets Management**: Use proper secret storage solutions
6. **Network Policies**: Control pod-to-pod communication
7. **RBAC**: Implement role-based access control

## CI/CD Integration

```yaml
# .github/workflows/deploy.yml
name: Build and Deploy

on:
  push:
    branches: [main]

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Build Docker image
        run: docker build -t myregistry.com/myapp:${{ github.sha }} .
      
      - name: Push to registry
        run: |
          echo ${{ secrets.REGISTRY_PASSWORD }} | docker login -u ${{ secrets.REGISTRY_USERNAME }} --password-stdin myregistry.com
          docker push myregistry.com/myapp:${{ github.sha }}
      
      - name: Deploy to Kubernetes
        run: |
          kubectl set image deployment/myapp myapp=myregistry.com/myapp:${{ github.sha }} -n production
          kubectl rollout status deployment/myapp -n production
```

## Conclusion

Docker and Kubernetes have become essential tools for modern application deployment. By containerizing your applications and leveraging Kubernetes for orchestration, you gain portability, scalability, and reliability.

Start with Docker for local development, graduate to Docker Compose for multi-container applications, and then move to Kubernetes when you need production-grade orchestration.

---

**Additional Resources:**

- [Docker Documentation](https://docs.docker.com/)
- [Kubernetes Documentation](https://kubernetes.io/docs/)
- [Docker Best Practices](https://docs.docker.com/develop/dev-best-practices/)
- [Kubernetes Patterns](https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/)
- [CNCF Landscape](https://landscape.cncf.io/)

